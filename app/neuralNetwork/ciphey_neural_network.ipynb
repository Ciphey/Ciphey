{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "CATEGORIES = [\"sha1\", \"md5\", \"sha256\", \"sha512\", \"caeser\", \"plaintext\"]\n",
    "CATEGORIES = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# minus 1 as it starts at 0\n",
    "sha1 = 1\n",
    "md5 = 2\n",
    "sha256 = 3\n",
    "sha512 = 4\n",
    "caeser = 5\n",
    "plaintext = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  your_list = list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "array([1.7000000e+01, 7.0000000e+00, 1.2983282e-04])\n",
      "[1.7000000e+01 7.0000000e+00 1.2983282e-04]\n",
      "[17.0, 7.0, 0.0001298328198294165]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "counter = 0.0\n",
    "totals = 0.00\n",
    "for item in your_list:\n",
    "    counter = counter + 1\n",
    "    y.append([item[-1]])\n",
    "    # delete y from it\n",
    "    del item[-1]\n",
    "    # delete the plaintext\n",
    "    del item[0]\n",
    "    # delete the encrypted text\n",
    "    del item[0]\n",
    "    # delete the array (this was causing me problems)\n",
    "    del item[2]\n",
    "    item[0] = float(item[0])\n",
    "    item[1] = float(item[1])\n",
    "    try:\n",
    "        item[2] = float(item[2])\n",
    "        totals = totals + item[2]\n",
    "    except ValueError as e:\n",
    "        item[2] = float(totals / counter)\n",
    "        \n",
    "    x.append(item)\n",
    "import pprint\n",
    "x_train = numpy.asarray(x)\n",
    "y_train = numpy.asarray(y)\n",
    "print(x_train[0].shape)\n",
    "pprint.pprint(x_train[0])\n",
    "print(x_train[0])\n",
    "print(list(x_train[0]))\n",
    "\n",
    "DONOTCHANGE = x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 13:25:25.552932 17436 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 152572 samples, validate on 38143 samples\n",
      "Epoch 1/5\n",
      "152572/152572 [==============================] - 12s 76us/sample - loss: 0.4923 - acc: 0.7895 - val_loss: 0.3466 - val_acc: 0.8402\n",
      "Epoch 2/5\n",
      "152572/152572 [==============================] - 11s 70us/sample - loss: 0.3592 - acc: 0.8375 - val_loss: 0.7731 - val_acc: 0.5684\n",
      "Epoch 3/5\n",
      "152572/152572 [==============================] - 11s 73us/sample - loss: 0.3429 - acc: 0.8418 - val_loss: 0.3296 - val_acc: 0.8456\n",
      "Epoch 4/5\n",
      "152572/152572 [==============================] - 11s 71us/sample - loss: 0.3361 - acc: 0.8441 - val_loss: 0.3538 - val_acc: 0.8419\n",
      "Epoch 5/5\n",
      "152572/152572 [==============================] - 11s 69us/sample - loss: 0.3309 - acc: 0.8453 - val_loss: 0.3186 - val_acc: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x192406a7e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(3,)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs = 5, batch_size = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"NeuralNetworkModel.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "new.append([17.0, 7.0, 0.0001298328198294165])\n",
    "new = numpy.asarray(new)\n",
    "#print(new.shape)\n",
    "y = model.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4']\n",
      "[7.913161559024217e-23, 1.2141825322942168e-08, 3.662281359884703e-27, 2.351118884879166e-26, 0.6163268685340881, 0.38367313146591187]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "numpy.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "print(y.tolist()[0])\n",
    "numpy.argmax(y.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\\nfrom keras import backend as K\\n#K.set_image_dim_ordering('th')\\n\\nmodel = Sequential()\\nprint(y_train.shape)\\nprint(x_train.shape)\\nx_train = x_train.reshape((1, 190715, 3, 1))\\ny_train = y_train.reshape((1, 190715, 3))\\ny_train = y_train[0]\\n\\n\\nmodel.add(Conv2D(64, (3, 3), input_shape = (190715, 3, 1)))\\n\\nmodel.add(tf.keras.layers.GlobalAveragePooling2D()) # change from flatten to GlobalAveragePooling2D()\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\\nmodel.add(tf.keras.layers.Dense(6, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\\n\\nmodel.compile(optimizer='adam',\\n              loss='sparse_categorical_crossentropy',  \\n              metrics=['accuracy'])\\n\\nprint(y_train)\\n\\nmodel.fit(x_train, y_train, epochs=1, batch_size = 25, validation_split=0.3)  # train the model\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "model = Sequential()\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape((1, 190715, 3, 1))\n",
    "y_train = y_train.reshape((1, 190715, 3))\n",
    "y_train = y_train[0]\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (190715, 3, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D()) # change from flatten to GlobalAveragePooling2D()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1, batch_size = 25, validation_split=0.3)  # train the model\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python37\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
