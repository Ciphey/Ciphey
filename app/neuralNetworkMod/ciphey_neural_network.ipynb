{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "CATEGORIES = [\"sha1\", \"md5\", \"sha256\", \"sha512\", \"caeser\", \"plaintext\"]\n",
    "CATEGORIES = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# minus 1 as it starts at 0\n",
    "sha1 = 1\n",
    "md5 = 2\n",
    "sha256 = 3\n",
    "sha512 = 4\n",
    "caeser = 5\n",
    "plaintext = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  your_list = list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "array([17.000000, 7.000000])\n",
      "[17.000000 7.000000]\n",
      "[17.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "counter = 0.0\n",
    "totals = 0.00\n",
    "for item in your_list:\n",
    "    counter = counter + 1\n",
    "    y.append([item[-1]])\n",
    "    # delete y from it\n",
    "    del item[-1]\n",
    "    # delete the plaintext\n",
    "    del item[0]\n",
    "    # delete the encrypted text\n",
    "    del item[0]\n",
    "    # delete the array (this was causing me problems)\n",
    "    del item[2]\n",
    "    item[0] = float(item[0])\n",
    "    item[1] = float(item[1])\n",
    "    del item[2]\n",
    "        \n",
    "    x.append(item)\n",
    "import pprint\n",
    "x_train = numpy.asarray(x)\n",
    "y_train = numpy.asarray(y)\n",
    "print(x_train[0].shape)\n",
    "pprint.pprint(x_train[0])\n",
    "print(x_train[0])\n",
    "print(list(x_train[0]))\n",
    "\n",
    "DONOTCHANGE = x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 152572 samples, validate on 38143 samples\n",
      "Epoch 1/3\n",
      "152572/152572 [==============================] - 51s 332us/sample - loss: 0.4829 - acc: 0.7931 - val_loss: 0.3424 - val_acc: 0.8452\n",
      "Epoch 2/3\n",
      "152572/152572 [==============================] - 33s 219us/sample - loss: 0.3583 - acc: 0.8389 - val_loss: 0.3409 - val_acc: 0.8424\n",
      "Epoch 3/3\n",
      "152572/152572 [==============================] - 42s 276us/sample - loss: 0.3399 - acc: 0.8431 - val_loss: 0.3313 - val_acc: 0.8455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cd7de43a58>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(2,)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs = 3, batch_size = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(text):\n",
    "    \"\"\"\n",
    "    formats the data\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    result.append(len(text))\n",
    "    result.append(len(list(set(list(text)))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"NeuralNetworkModel.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def editData(data):\n",
    "    \"\"\"\n",
    "    Data has to be in format:\n",
    "    * [length of text, how many unique letters it has, the normalised chi square score]\n",
    "    \"\"\"\n",
    "    new = []\n",
    "    new.append(formatData(data))\n",
    "    return numpy.asarray(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000000 0.000000 0.000002 0.999933 0.000037 0.000028]]\n"
     ]
    }
   ],
   "source": [
    "x = editData(\"9b71d224bd62f3785d96d46ad3ea3d73319bfbc2890caadae2dff72519673ca72323c3d99ba5c11d7c7acc6e14b8c5da0c4663475c2e5c3adef46f73bcdec043\")\n",
    "y = model.predict(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "numpy.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "print(numpy.argmax(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\\nfrom keras import backend as K\\n#K.set_image_dim_ordering('th')\\n\\nmodel = Sequential()\\nprint(y_train.shape)\\nprint(x_train.shape)\\nx_train = x_train.reshape((1, 190715, 3, 1))\\ny_train = y_train.reshape((1, 190715, 3))\\ny_train = y_train[0]\\n\\n\\nmodel.add(Conv2D(64, (3, 3), input_shape = (190715, 3, 1)))\\n\\nmodel.add(tf.keras.layers.GlobalAveragePooling2D()) # change from flatten to GlobalAveragePooling2D()\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\\nmodel.add(tf.keras.layers.Dense(6, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\\n\\nmodel.compile(optimizer='adam',\\n              loss='sparse_categorical_crossentropy',  \\n              metrics=['accuracy'])\\n\\nprint(y_train)\\n\\nmodel.fit(x_train, y_train, epochs=1, batch_size = 25, validation_split=0.3)  # train the model\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "model = Sequential()\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape((1, 190715, 3, 1))\n",
    "y_train = y_train.reshape((1, 190715, 3))\n",
    "y_train = y_train[0]\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (190715, 3, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D()) # change from flatten to GlobalAveragePooling2D()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1, batch_size = 25, validation_split=0.3)  # train the model\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\brandon\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\brandon\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\brandon\\anaconda3\\lib\\site-packages (from pydot) (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
