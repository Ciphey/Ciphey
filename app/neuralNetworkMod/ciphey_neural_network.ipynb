{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "NAME=\"run1\"\n",
    "tensorboard = TensorBoard(log_dir=\"logs/\".format(NAME))\n",
    "\n",
    "CATEGORIES = [\"sha1\", \"md5\", \"sha256\", \"sha512\", \"caeser\", \"plaintext\"]\n",
    "CATEGORIES = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# minus 1 as it starts at 0\n",
    "sha1 = 1\n",
    "md5 = 2\n",
    "sha256 = 3\n",
    "sha512 = 4\n",
    "caeser = 5\n",
    "plaintext = 6\n",
    "reverse = 7\n",
    "b64 = 8\n",
    "binary = 9\n",
    "hexade = 10\n",
    "asci = 11\n",
    "morse = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  your_list = list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "array([17.,  7.])\n",
      "[17.  7.]\n",
      "[17.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "counter = 0.0\n",
    "totals = 0.00\n",
    "for item in your_list:\n",
    "    counter = counter + 1\n",
    "    y.append([item[-1]])\n",
    "    # delete y from it\n",
    "    del item[-1]\n",
    "    # delete the plaintext\n",
    "    del item[0]\n",
    "    # delete the encrypted text\n",
    "    del item[0]\n",
    "    # delete the array (this was causing me problems)\n",
    "    del item[2]\n",
    "    item[0] = float(item[0])\n",
    "    item[1] = float(item[1])\n",
    "    del item[2]\n",
    "        \n",
    "    x.append(item)\n",
    "import pprint\n",
    "x_train = numpy.asarray(x)\n",
    "y_train = numpy.asarray(y)\n",
    "print(x_train[0].shape)\n",
    "pprint.pprint(x_train[0])\n",
    "print(x_train[0])\n",
    "print(list(x_train[0]))\n",
    "\n",
    "DONOTCHANGE = x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 14:24:55.319718  5768 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122140 samples, validate on 30535 samples\n",
      "Epoch 1/10\n",
      "122140/122140 [==============================] - 26s 210us/sample - loss: 0.6170 - acc: 0.7579 - val_loss: 0.4081 - val_acc: 0.8412\n",
      "Epoch 2/10\n",
      "122140/122140 [==============================] - 26s 216us/sample - loss: 0.4243 - acc: 0.8292 - val_loss: 0.3629 - val_acc: 0.8477\n",
      "Epoch 3/10\n",
      "122140/122140 [==============================] - 26s 210us/sample - loss: 0.3989 - acc: 0.8388 - val_loss: 0.3590 - val_acc: 0.8570\n",
      "Epoch 4/10\n",
      "122140/122140 [==============================] - 25s 207us/sample - loss: 0.3854 - acc: 0.8434 - val_loss: 0.3928 - val_acc: 0.8375\n",
      "Epoch 5/10\n",
      "122140/122140 [==============================] - 25s 208us/sample - loss: 0.3783 - acc: 0.8447 - val_loss: 0.4242 - val_acc: 0.8357\n",
      "Epoch 6/10\n",
      "122140/122140 [==============================] - 26s 215us/sample - loss: 0.3734 - acc: 0.8464 - val_loss: 0.3706 - val_acc: 0.8472\n",
      "Epoch 7/10\n",
      "122140/122140 [==============================] - 26s 212us/sample - loss: 0.3675 - acc: 0.8478 - val_loss: 0.3578 - val_acc: 0.8521\n",
      "Epoch 8/10\n",
      "122140/122140 [==============================] - 27s 217us/sample - loss: 0.3623 - acc: 0.8497 - val_loss: 0.4339 - val_acc: 0.8383\n",
      "Epoch 9/10\n",
      "122140/122140 [==============================] - 28s 230us/sample - loss: 0.3645 - acc: 0.8498 - val_loss: 0.3406 - val_acc: 0.8581\n",
      "Epoch 10/10\n",
      "122140/122140 [==============================] - 26s 214us/sample - loss: 0.3563 - acc: 0.8513 - val_loss: 0.3887 - val_acc: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12b53967f98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(2,)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs = 10, batch_size = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatData(text):\n",
    "    \"\"\"\n",
    "    formats the data\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    result.append(len(text))\n",
    "    result.append(len(list(set(list(text)))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"NeuralNetworkModel.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def editData(data):\n",
    "    \"\"\"\n",
    "    Data has to be in format:\n",
    "    * [length of text, how many unique letters it has, the normalised chi square score]\n",
    "    \"\"\"\n",
    "    new = []\n",
    "    new.append(formatData(data))\n",
    "    return numpy.asarray(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.95858990e-18 2.36542294e-15 9.70669234e-09 8.62388313e-01\n",
      "  1.81515861e-04 1.41059543e-04 1.29728416e-20 1.83715745e-08\n",
      "  7.70451880e-09 1.37285084e-01 3.96582027e-06 1.00919575e-08]]\n"
     ]
    }
   ],
   "source": [
    "x = editData(\"9b71d224bd62f3785d96d46ad3ea3d73319bfbc2890caadae2dff72519673ca72323c3d99ba5c11d7c7acc6e14b8c5da0c4663475c2e5c3adef46f73bcdec043\")\n",
    "y = model.predict(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "numpy.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "print(numpy.argmax(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tensorflow as tf\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\\nfrom keras import backend as K\\n#K.set_image_dim_ordering('th')\\n\\nmodel = Sequential()\\nprint(y_train.shape)\\nprint(x_train.shape)\\nx_train = x_train.reshape((1, 190715, 3, 1))\\ny_train = y_train.reshape((1, 190715, 3))\\ny_train = y_train[0]\\n\\n\\nmodel.add(Conv2D(64, (3, 3), input_shape = (190715, 3, 1)))\\n\\nmodel.add(tf.keras.layers.GlobalAveragePooling2D()) # change from flatten to GlobalAveragePooling2D()\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\\nmodel.add(tf.keras.layers.Dense(6, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\\n\\nmodel.compile(optimizer='adam',\\n              loss='sparse_categorical_crossentropy',  \\n              metrics=['accuracy'])\\n\\nprint(y_train)\\n\\nmodel.fit(x_train, y_train, epochs=1, batch_size = 25, validation_split=0.3)  # train the model\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "model = Sequential()\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape((1, 190715, 3, 1))\n",
    "y_train = y_train.reshape((1, 190715, 3))\n",
    "y_train = y_train[0]\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (190715, 3, 1)))\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D()) # change from flatten to GlobalAveragePooling2D()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(6, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1, batch_size = 25, validation_split=0.3)  # train the model\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\admin\\appdata\\roaming\\python\\python37\\site-packages (from keras) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydot) (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
